<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Pseudo RGB-D for Self-Improving Monocular SLAM and Depth Prediction | Dr. Lokender  Tiwari, Ph.D.</title>
    <meta name="author" content="Dr. Lokender  Tiwari, Ph.D.">
    <meta name="description" content="In European Conference on Computer Vision (&lt;b&gt;ECCV&lt;/b&gt;), 2020">
    <meta name="keywords" content="Lokender Tiwari, Dr. Lokender Tiwari, Computer Vision, Machine Learning, Artificial Intelligence, Deep Learning, Computer Graphics, Pseudo RGBD, NEC , IIIT Delhi, IIIT, TCS, TCS Research, Research, Cloth Animation, Metaverse, DGSAC, DeepDraper, GarSim, Lokendra, 3D Vision, 3D Computer Vision">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/projects/pseudo-rgbd-slam/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Dr. Lokender </span>Tiwari, Ph.D.</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Home</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Selected Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/photos/">Photos</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Pseudo RGB-D for Self-Improving Monocular SLAM and Depth Prediction</h1>
            <p class="post-description">In European Conference on Computer Vision (<b>ECCV</b>), 2020</p>
          </header>

          <article>
            <p><strong>Authors:</strong> <a href="https://lokender.github.io/" rel="external nofollow noopener" target="_blank">Lokender Tiwari</a><sup>1</sup>,  
<a href="https://sites.google.com/site/peterji1990" rel="external nofollow noopener" target="_blank">Pan Ji</a><sup>2</sup>,  
<a href="https://cs.adelaide.edu.au/~huy/home.php" rel="external nofollow noopener" target="_blank">Quoc-Huy Tran</a><sup>2</sup>,  
<a href="https://bbzh.github.io/" rel="external nofollow noopener" target="_blank">Bingbing Zhuang</a><sup>2</sup>,  
<a href="https://www.iiitd.edu.in/~anands/index.html" rel="external nofollow noopener" target="_blank">Saket Anand</a><sup>1</sup>,  
<a href="https://cseweb.ucsd.edu/~mkchandraker/" rel="external nofollow noopener" target="_blank">Manmohan Chandraker</a><sup>2,3</sup></p>

<p><strong>Affiliations:</strong> <sup>1</sup><a href="https://www.iiitd.ac.in/" rel="external nofollow noopener" target="_blank">IIIT-Delhi</a>,  
<sup>2</sup><a href="http://www.nec-labs.com/research-departments/media-analytics/media-analytics-home" rel="external nofollow noopener" target="_blank">NEC Labs America, Inc.</a>,  
<sup>3</sup><a href="https://ucsd.edu/" rel="external nofollow noopener" target="_blank">UCSD</a></p>

<p><strong>Links:</strong> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560426.pdf" rel="external nofollow noopener" target="_blank">PDF</a>,  
<a href="https://arxiv.org/pdf/2004.10681" rel="external nofollow noopener" target="_blank">arXiv</a>,  
<a href="https://www.youtube.com/watch?v=N9Di1uN0ut0&amp;list=PL-cvWulnEGU6gBmgr8leVbJ6k7aI3MTjA" rel="external nofollow noopener" target="_blank">Conference Talk and Demos</a>,  
<a href="/assets/pdf/pRGBD_ECCV_Main_Talk.pdf">Conference Talk Slides</a>,  
<a href="/assets/pdf/pRGBD_ECCV_Demo_Talk.pdf">Demo Talk Slides</a>,  </p>

<hr>

<h2 id="abstract">Abstract</h2>
<blockquote>
  <p>Classical monocular Simultaneous Localization And Mapping (SLAM) and the recently emerging convolutional neural networks (CNNs) for monocular depth prediction represent two largely disjoint approaches towards building a 3D map of the surrounding environment. In this paper, we demonstrate that the coupling of these two by leveraging the strengths of each mitigates the others shortcomings. Specifically, we propose a joint narrow and wide baseline based self-improving framework, where on the one hand the CNN-predicted depth is leveraged to perform pseudo RGB-D feature-based SLAM, leading to better accuracy and robustness than the monocular RGB SLAM baseline. On the other hand, the bundleadjusted 3D scene structures and camera poses from the more principled geometric SLAM are injected back into the depth network through novel wide baseline losses proposed for improving the depth prediction network, which then continues to contribute towards better pose and 3D structure estimation in the next iteration. We emphasize that our framework only requires unlabeled monocular videos in both training and inference stages, and yet is able to outperform state-of-the-art self-supervised monocular and stereo depth prediction networks (e.g., Monodepth2) and feature-based monocular SLAM system (i.e., ORB-SLAM). Extensive experiments on KITTI and TUM RGB-D datasets verify the superiority of our self-improving geometry-CNN framework.</p>
</blockquote>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/self_improving_framework-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/self_improving_framework-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/self_improving_framework-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/self_improving_framework.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Figure 1:</b> A SELF-SUPERVISED, SELF-IMPROVING FRAMEWORK -- It alternates between pose refinement (blue arrows) and depth refinement (red arrows). </h6>
    
</div>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <iframe display="block" width="640" height="320" src="https://www.youtube.com/embed/N9Di1uN0ut0?autoplay=1"> </iframe> 
    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>ECCV 2020 Conference Talk</b>
</h6>
</div>

<hr>

<h3 style="text-align:center"> <b>ECCV 2020 Demo Track : RGB vs Pseudo RGB-D SLAM and Monocular Depth Prediction Demos</b> </h3>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <iframe display="block" width="640" height="320" src="https://www.youtube.com/embed/gdY4yn0J4E0?autoplay=1"> </iframe> 
    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Video 1:</b> KITTI Odometry Sequence 19 </h6>
</div>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <iframe display="block" width="640" height="320" src="https://www.youtube.com/embed/OOPJpHexrdE?autoplay=1"> </iframe> 
    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Video 2:</b> KITTI Odometry Sequence 11 </h6>
</div>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <iframe display="block" width="640" height="320" src="https://www.youtube.com/embed/MffXsKjy9W0?autoplay=1"> </iframe> 
    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Video 3:</b> TUM RGB-D Sequence freiburg3 Large Cabinet Validation. </h6>
</div>

<hr>

<h3 style="text-align:center"> <b>Results: Qualitative Depth Estimation</b> </h3>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/qual_depth_far-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/qual_depth_far-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/qual_depth_far-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/qual_depth_far.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Figure 2:</b> Qualitative depth evaluation results on KITTI Odometry test set. Improvement in depth prediction of farther scene points. </h6>
</div>

<p> </p>

<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/qual_depth-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/qual_depth-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/qual_depth-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/qual_depth.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Figure 3:</b> Qualitative depth evaluation results on KITTI Raw Eigen split test set. MonoDepth2-M is the MonoDepth2 model trained using monocular images. </h6>
</div>
<hr>

<h3 style="text-align:center"> <b>Results: Qualitative Pose Estimation Results</b> </h3>
<div class="row justify-content-md-center">
    <div class="col-md-auto">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/qual_pose_kitti-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/qual_pose_kitti-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/qual_pose_kitti-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/qual_pose_kitti.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    <h6 style="text-align:center"> <b>Figure 4:</b> Qualitative pose evaluation results on KITTI Odometry sequences. </h6>
</div>

<hr>

<h4>Bibtex</h4>
<pre>@inproceedings{tiwari2020pseudo,
    author={Tiwari, Lokender and Ji, Pan and Tran, Quoc-Huy and Zhuang, Bingbing and Anand, Saket 
    and Chandraker, Manmohan},
    title     = {Pseudo RGB-D for Self-Improving Monocular SLAM and Depth Prediction}, 
    booktitle = {European Conference on Computer Vision},
    year      = {2020}
}
</pre>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Dr. Lokender  Tiwari, Ph.D.. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-7728JLJD0V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-7728JLJD0V');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
